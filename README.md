# ğŸŒ¦ï¸ Weather Data Pipeline with AWS & Snowflake

This project is a serverless data pipeline that ingests weather data from a public API and processes it using AWS services (Lambda, DynamoDB, S3) before loading it into Snowflake for analytics and reporting.

---

## ğŸ”§ Architecture Overview

![Architecture Diagram](project.png)

---

## ğŸš€ Features

- â° **Automated ingestion**: Weather data fetched on a schedule using AWS Lambda.
- ğŸ§± **Raw data storage**: Stored in DynamoDB with streaming enabled.
- ğŸ“¦ **Stream to S3**: Real-time Lambda stream handler processes and uploads data to S3.
- â„ï¸ **Snowflake integration**: S3 bucket is mounted in Snowflake as an external stage for querying.
- ğŸ”’ **Secure IAM roles and trust policies**

---

## ğŸ› ï¸ Tech Stack

- **AWS Lambda** â€“ Serverless compute
- **DynamoDB** â€“ NoSQL storage for raw weather data
- **S3** â€“ Data lake storage for processed streams
- **Snowflake** â€“ Scalable cloud data warehouse
- **Python + Boto3** â€“ Scripting and AWS SDK
- **CloudWatch** â€“ Monitoring and logging

---

## ğŸ“ Folder Structure

weather-pipeline/
â”‚
â”œâ”€â”€ lambda_ingestor/ # Fetches weather data from API
â”‚ â””â”€â”€ handler.py
â”‚
â”œâ”€â”€ lambda_stream_to_s3/ # Processes DynamoDB stream and stores in S3
â”‚ â””â”€â”€ handler.py
â”‚
â”œâ”€â”€ utils/ # Helper utilities
â”‚ â””â”€â”€ s3_utils.py
â”‚
â”œâ”€â”€ snowflake/ # Snowflake SQL scripts
â”‚ â””â”€â”€ create_stage.sql
â”‚
â”œâ”€â”€ diagram/ # Architecture diagram
â”‚ â””â”€â”€ weather_pipeline_diagram.png
â”‚
â””â”€â”€ README.md # This file


---

## ğŸ“Š Sample Output (Snowflake Table)

| City      | Temp (Â°C) | Condition  | Timestamp           |
|-----------|-----------|------------|---------------------|
| Lahore    | 32.5      | Clear Sky  | 2025-05-30 08:00:00 |
| Karachi   | 29.0      | Humid      | 2025-05-30 08:00:00 |

---

## ğŸš€ Setup Instructions

1. Clone the repository:
    ```bash
    git clone https://github.com/zainalvi110/WeatherData-AWS-Snowflake-DataPipeline.git
    ```

2. Install dependencies:
    ```bash
    pip install boto3 requests
    ```

3. Deploy the Lambda functions using AWS Console or SAM/Serverless Framework.

4. Set up Snowflake external stage and define your table using provided SQL.

---

## ğŸ§  Author

**Zain Alvi**  
[LinkedIn](https://www.linkedin.com/in/yourprofile)  
[Portfolio](https://yourportfolio.com)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.


